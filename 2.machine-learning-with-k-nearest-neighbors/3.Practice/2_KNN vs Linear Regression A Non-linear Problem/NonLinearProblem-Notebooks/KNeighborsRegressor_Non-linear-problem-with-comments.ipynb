{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cde33d0",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Regressor - A non-linear problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca7d1f",
   "metadata": {},
   "source": [
    "### Importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba381a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will help us split the data into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This class will help us create a KNN regression model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# This class will help us create a Linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# This method will help us calculate the mean squared error for each model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# This library will help us organize our data\n",
    "import pandas as pd\n",
    "\n",
    "# We import the sine function which will help us generate our non-linear data\n",
    "from math import sin\n",
    "\n",
    "# Import the numpy library\n",
    "import numpy as np\n",
    "\n",
    "# These libraries will help us visualize the results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015994d2",
   "metadata": {},
   "source": [
    "### Defining the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b636c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that generates a random non-linear dataset\n",
    "def non_linear_regression(n_samples, noise = 0, random_state = None):\n",
    "    \n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    uni = lambda n : np.random.uniform(-2, 2, n)\n",
    "    add_noise =  lambda  n : np.random.normal(0, 1, n)\n",
    "    \n",
    "    x = []\n",
    "    x = uni(n_samples)\n",
    "    x.sort()\n",
    "    \n",
    "    y_raw = [i**2 + sin(5*i) for i in x]\n",
    "    y = y_raw + noise * np.std(y_raw) * add_noise(n_samples)\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ebddc6",
   "metadata": {},
   "source": [
    "### Display the data with and without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data without noise\n",
    "inputs_no_noise, target_no_noise = non_linear_regression(300, 0, 365)\n",
    "\n",
    "# Using the same random state as above, generate the data with some noise\n",
    "inputs, target = non_linear_regression(300, 0.5, 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9249ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seaborn visualization\n",
    "sns.set()\n",
    "\n",
    "# Create a placeholder for 2 subplots aligned horizontally\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13,4))\n",
    "\n",
    "# Plot the noiseless data, choose the color of the datapoints\n",
    "# Set a title and axes labels\n",
    "ax1.scatter(inputs_no_noise, target_no_noise, color = '#000C1F')\n",
    "ax1.set_title('Data without noise')\n",
    "ax1.set_xlabel('Feature')\n",
    "ax1.set_ylabel('Target')\n",
    "\n",
    "# Plot the noisy data, choose the color of the datapoints\n",
    "# Set a title and axes labels\n",
    "ax2.scatter(inputs, target, color = '#000C1F')\n",
    "ax2.set_title('Data with noise')\n",
    "ax2.set_xlabel('Feature')\n",
    "ax2.set_ylabel('Target');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a016827a",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets. Visualize both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b041b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets such that 20% of all points are dedicated to testing.\n",
    "# Set a random state so that the split is reproducible.\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, \n",
    "                                                    target, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d056623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seaborn visualization\n",
    "sns.set()\n",
    "\n",
    "# Create a placeholder for two subplots which are aligned horizontally. Set a specific size for the figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13,4))\n",
    "\n",
    "# Plot the training data\n",
    "ax1.scatter(x_train, y_train, color = '#000C1F')\n",
    "ax1.set_title('Training data')\n",
    "ax1.set_xlabel('Feature')\n",
    "ax1.set_ylabel('Target')\n",
    "\n",
    "# Plot the test data\n",
    "ax2.scatter(x_test, y_test, color = '#000C1F')\n",
    "ax2.set_title('Test data')\n",
    "ax2.set_xlabel('Feature')\n",
    "ax2.set_ylabel('Target');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38ade6",
   "metadata": {},
   "source": [
    "### Fit a linear regression and multiple KNN-regressions. Calculate the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b33141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an intance of the Linear regression class\n",
    "reg_lin = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data.\n",
    "# In sklearn, when fitting data with only 1 feature, the following reshaping should be applied.\n",
    "reg_lin.fit(x_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Make predictions on the test data.\n",
    "# The same reshaping should be applied.\n",
    "y_pred_lin = reg_lin.predict(x_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53cb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a maximum number of nearest neighbors and add 1. \n",
    "# That is, choose the value 81 to set a maximum value of 80.\n",
    "# The reason we add the 1 is because this number is then used in a range() function in the following way:\n",
    "# range(1, k)\n",
    "# The range() function includes the first number but excludes the second one.\n",
    "k = 81\n",
    "\n",
    "# Create an array where all mean-squared error (MSE) values from the linear regression will be stored.\n",
    "mse_lin = []\n",
    "\n",
    "# Calculate the MSE value for the linear regression\n",
    "mse_lin = mean_squared_error(y_test, y_pred_lin)\n",
    "\n",
    "# The MSE value calculated above is the same for all values of K. \n",
    "# Therefore, we create an array storing that MSE value (k-1) many times.\n",
    "# This will later be used to plot the MSE value versus the number of nearest neighbors.\n",
    "mse_lin = [mse_lin]*(k-1)\n",
    "\n",
    "# Create an array where all MSE values from the KNN regressions will be stored.\n",
    "mse_knn = []\n",
    "\n",
    "# Loop through all K-values\n",
    "for i in range(1, k):\n",
    "    \n",
    "    # Create an instance of the KNN regression for the specified value of K\n",
    "    reg_knn = KNeighborsRegressor(n_neighbors = i)\n",
    "    \n",
    "    # Fir the training data to the model\n",
    "    reg_knn.fit(x_train.reshape(-1, 1), y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred_knn = reg_knn.predict(x_test.reshape(-1, 1))\n",
    "    \n",
    "    # Calculate the MSE value for this regression and store it in the array\n",
    "    mse_knn.append(mean_squared_error(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d023a23",
   "metadata": {},
   "source": [
    "### Plot the MSE versus the number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcce0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seaborn visualization\n",
    "sns.set()\n",
    "\n",
    "# Create a placeholder for a figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the MSE of the linear regression versus the value of K.\n",
    "# Since the linear regression is not affected by the value of K, the output is a straight line.\n",
    "# Choose a color.\n",
    "# Choose a label which will describe the line in the legend\n",
    "plt.plot(list(range(1, k)), \n",
    "         mse_lin, \n",
    "         color = 'orange', \n",
    "         label = 'linear')\n",
    "\n",
    "# Plot the MSE of the KNN regressions versus the value of K.\n",
    "# Choose a color for the line.\n",
    "# Use a marker to show the values of K.\n",
    "# Choose a color for the marker\n",
    "# Choose a label which will describe the line in the legend\n",
    "plt.plot(list(range(1, k)), \n",
    "         mse_knn, \n",
    "         color = 'red', \n",
    "         marker = 'o', \n",
    "         markerfacecolor = '#000C1F',\n",
    "         label = 'KNN')\n",
    "\n",
    "# Place the legend in the lower right corner\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# Set a title and axes labes\n",
    "ax.set_title('Mean-Squared Error (MSE)')\n",
    "ax.set_xlabel('K')\n",
    "ax.set_ylabel('MSE')\n",
    "\n",
    "# Set a minimum value of the y-axis\n",
    "plt.ylim(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292823ed",
   "metadata": {},
   "source": [
    "### Make predictions only for K = 1, 7, and 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c6daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the predictions from 3 KNN regressions\n",
    "y_pred_knn = []\n",
    "\n",
    "# Create 3 KNN regressions with K = 1, 7, and 80.\n",
    "# Fit the model to the training data\n",
    "# Make predictions on the test data\n",
    "for i in [1, 7, 80]:\n",
    "    reg_knn = KNeighborsRegressor(n_neighbors = i)\n",
    "    reg_knn.fit(x_train.reshape(-1, 1), y_train)\n",
    "    y_pred_knn.append(reg_knn.predict(x_test.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f639299",
   "metadata": {},
   "source": [
    "### Sort the data according to the test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to visualize the regressions well, we need to sort the data with respect to the test features\n",
    "\n",
    "df = pd.DataFrame(data = {'x_test':list(x_test.flatten()), \n",
    "                          'y_test':list(y_test.flatten()), \n",
    "                          'y_pred_lin':list(y_pred_lin.flatten()), \n",
    "                          'y_pred_knn-1':list(y_pred_knn[0].flatten()), \n",
    "                          'y_pred_knn-7':list(y_pred_knn[1].flatten()), \n",
    "                          'y_pred_knn-80':list(y_pred_knn[2].flatten())})\n",
    "\n",
    "# To check how the visualization looks like without sorting the data, comment out the line below,\n",
    "# run the cell and then run the next 2 cells.\n",
    "df = df.sort_values(by = ['x_test'])\n",
    "\n",
    "x_test_sorted = df['x_test'].tolist()\n",
    "y_test_sorted = df['y_test'].tolist()\n",
    "y_pred_lin_sorted = df['y_pred_lin'].tolist()\n",
    "y_pred_knn1_sorted = df['y_pred_knn-1'].tolist()\n",
    "y_pred_knn7_sorted = df['y_pred_knn-7'].tolist()\n",
    "y_pred_knn80_sorted = df['y_pred_knn-80'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0917e",
   "metadata": {},
   "source": [
    "### Plot the regressions on top of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac993ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seaborn visualization\n",
    "sns.set()\n",
    "\n",
    "# Create a placeholder for two figures aligned horizontally\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "# Plot the sorted test data on the left figure\n",
    "ax1.scatter(x_test_sorted, \n",
    "            y_test_sorted, \n",
    "            color = '#000C1F')\n",
    "\n",
    "# Plot the fit from the linear regression\n",
    "ax1.plot(x_test_sorted, \n",
    "         y_pred_lin_sorted, \n",
    "         color = 'orange')\n",
    "\n",
    "# Add a title and axes labels to the left figure\n",
    "ax1.set_title('Linear fit on top of the test data')\n",
    "ax1.set_xlabel('Feature')\n",
    "ax1.set_ylabel('Target')\n",
    "\n",
    "# Plot the sorted test data on the right figure\n",
    "ax2.scatter(x_test_sorted, \n",
    "            y_test_sorted, \n",
    "            color = '#000C1F')\n",
    "\n",
    "# Plot the fit from the KNN regression (K = 7)\n",
    "ax2.plot(x_test_sorted, \n",
    "         y_pred_knn7_sorted, \n",
    "         color = 'red', \n",
    "         marker = 'o', \n",
    "         markerfacecolor = 'yellow')\n",
    "\n",
    "# Add a title and axes labels to the left figure\n",
    "ax2.set_title('KNN fit on top of the test data (K = 7)')\n",
    "ax2.set_xlabel('Feature')\n",
    "ax2.set_ylabel('Target');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da38a842",
   "metadata": {},
   "source": [
    "### Plot the regressions for K = 1, 7, and 80 on top of the noiseless data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seaborn visualization\n",
    "sns.set()\n",
    "\n",
    "# Create a placeholder for 3 figures aligned horizontally\n",
    "fig, (ax1,ax2, ax3) = plt.subplots(1,3, figsize=(16, 5))\n",
    "\n",
    "# Plot the noiseless data on all 3 figures\n",
    "ax1.scatter(inputs_no_noise, target_no_noise, color = '#000C1F')\n",
    "ax2.scatter(inputs_no_noise, target_no_noise, color = '#000C1F')\n",
    "ax3.scatter(inputs_no_noise, target_no_noise, color = '#000C1F')\n",
    "\n",
    "# Plot the fit from a KNN regression (K = 1)\n",
    "ax1.plot(x_test_sorted, \n",
    "         y_pred_knn1_sorted, \n",
    "         color = 'red',\n",
    "         marker = 'o', \n",
    "         markerfacecolor = 'yellow')\n",
    "ax1.set_title('K = 1')\n",
    "ax1.set_xlabel('Feature')\n",
    "ax1.set_ylabel('Target')\n",
    "\n",
    "# Plot the fit from a KNN regression (K = 7)\n",
    "ax2.plot(x_test_sorted, \n",
    "         y_pred_knn7_sorted, \n",
    "         color = 'red',\n",
    "         marker = 'o', \n",
    "         markerfacecolor = 'yellow')\n",
    "ax2.set_title('K = 7')\n",
    "ax2.set_xlabel('Feature')\n",
    "ax2.set_ylabel('Target')\n",
    "\n",
    "# Plot the fit from a KNN regression (K = 80)\n",
    "ax3.plot(x_test_sorted, \n",
    "         y_pred_knn80_sorted, \n",
    "         color = 'red',\n",
    "         marker = 'o', \n",
    "         markerfacecolor = 'yellow')\n",
    "ax3.set_title('K = 80')\n",
    "ax3.set_xlabel('Feature')\n",
    "ax3.set_ylabel('Target');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
